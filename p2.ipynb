{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relationship Analysis & Feature Vetting for Machine Learning\n",
    "\n",
    "This notebook focuses on how variables relate to each other and how those relationships inform:\n",
    "- Feature selection\n",
    "- Model choice\n",
    "- Data preprocessing decisions\n",
    "\n",
    "We move beyond single-variable analysis and into:\n",
    "- Pairwise relationships\n",
    "- Correlation structure\n",
    "- Group comparisons\n",
    "- Statistical significance\n",
    "- Practical significance (effect size)\n",
    "- Feature usefulness for classification\n",
    "\n",
    "This is the bridge between Exploratory Data Analysis (EDA) and Modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in libraries and data sets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats # statistics machine\n",
    "df = pd.read_csv(\"Music_Data.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatterplots (Form, Direction, Strength, Linearity)\n",
    "\n",
    "We use scatterplots to visually assess:\n",
    "- Form (linear, curved, clustered, random)\n",
    "- Direction (positive, negative, none)\n",
    "- Strength (tight vs diffuse)\n",
    "- Linearity (can we use linear models?)\n",
    "\n",
    "If this relationship is roughly linear: Linear Regression is viable  \n",
    "If curved: we should consider polynomial or tree-based models  \n",
    "If cloud: weak predictive power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(df[\"tempo\"], df[\"loudness\"])\n",
    "plt.xlabel(\"Tempo\")\n",
    "plt.ylabel(\"Loudness\")\n",
    "plt.title(\"Tempo vs Loudness\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pair plots allow us to quickly detect:\n",
    "- Redundant features\n",
    "- Strong relationships\n",
    "- Completely uninformative features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df[[\"tempo\", \"loudness\", \"energy\", \"danceability\"]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Covariance shows whether two variables move together or in opposite directions.\n",
    "However, because it depends on units, it is hard to interpret directly.\n",
    "This is why we prefer correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_matrix = df[[\"tempo\", \"loudness\", \"energy\", \"danceability\"]].cov()\n",
    "cov_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Highly correlated features (|r| > 0.9) often contain redundant information.\n",
    "Keeping both can:\n",
    "- Increase model complexity\n",
    "- Increase overfitting risk\n",
    "\n",
    "In practice, we often drop one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df[[\"tempo\", \"loudness\", \"energy\", \"danceability\"]].corr()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This line represents the **baseline linear model**.\n",
    "The vertical distances from each point to the line are **residuals**.\n",
    "The algorithm's job is to minimize these.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[\"tempo\"]\n",
    "y = df[\"loudness\"]\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x, slope*x + intercept)\n",
    "plt.xlabel(\"Tempo\")\n",
    "plt.ylabel(\"Loudness\")\n",
    "plt.title(\"Least Squares Regression Line: Tempo vs Loudness\")\n",
    "plt.show()\n",
    "\n",
    "r_value**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Genre is the target <br>\n",
    "These are gut-check metrics.<br>\n",
    "If differences are tiny → model will struggle.<br>\n",
    "If differences are large → strong candidate feature.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rock = df[df[\"genre\"] == \"Rock\"][\"loudness\"]\n",
    "jazz = df[df[\"genre\"] == \"Jazz\"][\"loudness\"]\n",
    "\n",
    "#mean diff\n",
    "mean_diff = rock.mean() - jazz.mean()\n",
    "mean_diff\n",
    "\n",
    "# % change\n",
    "percent_change = (mean_diff / jazz.mean()) * 100\n",
    "percent_change\n",
    "\n",
    "# fold change\n",
    "fold_change = rock.mean() / jazz.mean()\n",
    "fold_change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation:\n",
    "- ~0.2 → small effect (weak feature)\n",
    "- ~0.5 → medium effect\n",
    "- ≥0.8 → large effect (\"gold mine\" feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohens_d(a, b):\n",
    "    pooled_std = np.sqrt((np.std(a, ddof=1) ** 2 + np.std(b, ddof=1) ** 2) / 2)\n",
    "    return (np.mean(a) - np.mean(b)) / pooled_std\n",
    "\n",
    "d = cohens_d(rock, jazz)\n",
    "d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing – Is the Difference Real?\n",
    "\n",
    "t-test (parametric)\n",
    "- p < 0.05 → difference is statistically significant\n",
    "- p ≥ 0.05 → difference may be noise\n",
    "\n",
    "Mann-Whitney U (non-parametric)\n",
    "- This test is safer for skewed, messy, real-world data (like audio features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-test\n",
    "t_stat, p_val = stats.ttest_ind(rock, jazz, equal_var=False)\n",
    "t_stat, p_val\n",
    "\n",
    "#Mann-Whitney\n",
    "u_stat, p_val_u = stats.mannwhitneyu(rock, jazz, alternative=\"two-sided\")\n",
    "u_stat, p_val_u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANOVA – Multi-Group Comparison\n",
    "ANOVA checks if the variation between genres is larger than the variation within genres?<br>\n",
    "\n",
    "If NO → this feature is likely noise. <br>\n",
    "If YES → strong candidate feature.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = [group[\"tempo\"].values for name, group in df.groupby(\"genre\")]\n",
    "\n",
    "f_stat, p_val = stats.f_oneway(*groups)\n",
    "f_stat, p_val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization – Preparing Fair Comparisons\n",
    "Min-Max scaling puts all features on [0,1].\n",
    "This allows us to:\n",
    "- Compare them visually\n",
    "- Prevent scale dominance in models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_features = scaler.fit_transform(df[[\"tempo\", \"loudness\", \"energy\"]])\n",
    "\n",
    "scaled_df = pd.DataFrame(scaled_features, columns=[\"tempo_scaled\", \"loudness_scaled\", \"energy_scaled\"])\n",
    "scaled_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we can now:\n",
    "\n",
    "- Eliminate deadweight features (no group difference, no correlation, no effect size)\n",
    "- Remove redundant features (highly correlated)\n",
    "- Prioritize high-signal features (large effect size + significant tests)\n",
    "- Choose appropriate model families:\n",
    "    - Linear relationships → Linear / Logistic Regression\n",
    "    - Nonlinear relationships → Trees, SVM, Neural Nets\n",
    "    - Weak separation → Expect lower ceiling performance\n",
    "\n",
    "This step prevents:\n",
    "- Garbage-in-garbage-out modeling\n",
    "- Overfitting\n",
    "- Wasted training time\n",
    "- Misleading accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_scores = []\n",
    "\n",
    "for col in [\"tempo\", \"loudness\", \"energy\", \"danceability\"]:\n",
    "    groups = [group[col].values for name, group in df.groupby(\"genre\")]\n",
    "    f_stat, p_val = stats.f_oneway(*groups)\n",
    "    feature_scores.append((col, f_stat, p_val))\n",
    "\n",
    "rank_df = pd.DataFrame(feature_scores, columns=[\"Feature\", \"F-statistic\", \"p-value\"])\n",
    "rank_df.sort_values(by=\"F-statistic\", ascending=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
